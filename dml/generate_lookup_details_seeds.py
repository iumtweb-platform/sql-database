from __future__ import annotations

import csv
from pathlib import Path


ROOT = Path(__file__).resolve().parents[1]
INPUT_DIR = ROOT / "data-import" / "output"
OUTPUT_DIR = ROOT / "dml" / "seeds"


MAPPINGS = [
    # number, source filename, table name, value column
    ("001", "details/type_distinct.csv", "type", "type"),
    ("002", "details/rating_distinct.csv", "rating", "rating"),
    ("003", "details/season_distinct.csv", "season", "season"),
    ("004", "details/source_distinct.csv", "source", "source"),
    ("005", "details/status_distinct.csv", "status", "status"),
    ("006", "details/genres_distinct.csv", "genre", "genre"),
    ("007", "details/explicit_genres_distinct.csv", "explicit_genre", "explicit_genre"),
    ("008", "details/licensors_distinct.csv", "licensor", "licensor"),
    ("009", "details/demographics_distinct.csv", "demographic", "demographic"),
    ("010", "details/producers_distinct.csv", "producer", "producer"),
    ("011", "details/streaming_distinct.csv", "streaming_service", "streaming_service"),
    ("012", "details/studios_distinct.csv", "studio", "studio"),
    ("013", "details/themes_distinct.csv", "theme", "theme"),
    ("014", "character_anime_works/role_distinct.csv", "character_role", "role"),
    ("015", "profiles/gender_distinct.csv", "gender", "gender"),
    ("016", "profiles/location_distinct.csv", "country", "country"),
    ("017", "person_voice_works/language_distinct.csv", "language", "language"),
]


def sql_escape(value: str) -> str:
    return value.replace("'", "''")


def read_distinct_values(file_path: Path) -> list[tuple[int, str]]:
    rows: list[tuple[int, str]] = []
    with file_path.open("r", encoding="utf-8", newline="") as handle:
        reader = csv.DictReader(handle)
        required = {"id", "value"}
        headers = set(reader.fieldnames or [])
        if not required.issubset(headers):
            raise ValueError(f"CSV must contain columns {sorted(required)}: {file_path}")

        for row in reader:
            raw_id = (row.get("id") or "").strip()
            raw_value = (row.get("value") or "").strip()
            if not raw_id or not raw_value:
                continue
            try:
                parsed_id = int(raw_id)
            except ValueError as exc:
                raise ValueError(f"Invalid id '{raw_id}' in {file_path}") from exc
            rows.append((parsed_id, raw_value))
    return rows


def render_seed_sql(table_name: str, value_column: str, rows: list[tuple[int, str]]) -> str:
    header = [
        f"-- Seed data for table: {table_name}",
        "-- Generated by dml/generate_lookup_details_seeds.py",
        "",
    ]

    if not rows:
        header.append(f"-- No values found for {table_name}; nothing to insert.")
        header.append("")
        return "\n".join(header)

    tuples = [
        f"    ({row_id}, '{sql_escape(value)}')"
        for row_id, value in rows
    ]

    body = [
        f"INSERT INTO {table_name} (id, {value_column}) VALUES",
        ",\n".join(tuples),
        "ON CONFLICT (id) DO NOTHING;",
        "",
    ]

    return "\n".join(header + body)


def main() -> None:
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    for number, source_filename, table_name, value_column in MAPPINGS:
        source_path = INPUT_DIR / source_filename
        if not source_path.exists():
            raise FileNotFoundError(f"Missing source file: {source_path}")

        rows = read_distinct_values(source_path)
        sql = render_seed_sql(table_name, value_column, rows)

        out_filename = f"{number}_{table_name}_seed.sql"
        out_path = OUTPUT_DIR / out_filename
        out_path.write_text(sql, encoding="utf-8")

        print(f"Wrote {out_path.relative_to(ROOT)} ({len(rows)} rows)")


if __name__ == "__main__":
    main()
